{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Similarity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to run this code first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Natural language processing is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language.\"\n",
    "\n",
    "sentence_collection = [\n",
    "    'Natural language processing is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language.',\n",
    "\n",
    "    'Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`sent_tokenize` is used to tokenize a text into sentences**\n",
    "- It accepts only a single string at a time. It does not accept a collection of string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing is an interdisciplinary subfield of computer science and linguistics.',\n",
       " 'It is primarily concerned with giving computers the ability to support and manipulate human language.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing is an interdisciplinary subfield of computer science and linguistics.', 'It is primarily concerned with giving computers the ability to support and manipulate human language.']\n",
      "['Natural language processing has its roots in the 1950s.', 'Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence.', 'The proposed test includes a task that involves the automated interpretation and generation of natural language.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentence_collection:\n",
    "    print(sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`word_tokenize` is used to tokenize a sentence or a piece of text into words.**\n",
    "- It accepts only a single string at a time. It does not accept a collection of string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = [\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "    \"Great Secrets of Amazon\",\n",
    "    \"S\",\n",
    "    \"Ss\",\n",
    "    \"7x7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', '#', 'and', 'the', 'Sorcerer', \"'s\", 'Stone']\n",
      "['Harry', 'Potter', '#', '2', 'and', 'the', 'Chamber', 'of', 'Secrets']\n",
      "['The', 'Sorcerer', \"'s\", 'Den', '!', '5s']\n",
      "['Great', '!', 'Sorcerer', \"'s\", 'of', 'NY', '2']\n",
      "['Great', 'Secrets', 'of', 'Amazon']\n",
      "['S']\n",
      "['Ss']\n",
      "['7x7']\n"
     ]
    }
   ],
   "source": [
    "for doc in docs1:\n",
    "    print(word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Structured way of creating tokenized list of documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['harry', 'potter', '#', 'and', 'the', 'sorcerer', \"'s\", 'stone'],\n",
       " ['harry', 'potter', '#', '2', 'and', 'the', 'chamber', 'of', 'secrets'],\n",
       " ['the', 'sorcerer', \"'s\", 'den', '!', '5s'],\n",
       " ['great', '!', 'sorcerer', \"'s\", 'of', 'ny', '2'],\n",
       " ['great', 'secrets', 'of', 'amazon'],\n",
       " ['s'],\n",
       " ['ss'],\n",
       " ['7x7']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_documents = [word_tokenize(document.lower()) for document in docs1]\n",
    "tokenized_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a smart word tokenizer which understand sentences properly and can differentiate between words and punctuations and also consider them as valid tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `BM25Okapi` takes only tokenized collection of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We get the scores as 1D array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.15792005, 2.68086623, 0.        , 0.77615639, 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Harry Potter #2\"\n",
    "\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harry Potter #2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Harry Potter # and the Sorcerer's Stone</th>\n",
       "      <td>2.157920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter #2 and the Chamber of Secrets</th>\n",
       "      <td>2.680866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sorcerer's Den! 5s</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great! Sorcerer's of NY 2</th>\n",
       "      <td>0.776156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Secrets of Amazon</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ss</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7x7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Harry Potter #2\n",
       "Harry Potter # and the Sorcerer's Stone            2.157920\n",
       "Harry Potter #2 and the Chamber of Secrets         2.680866\n",
       "The Sorcerer's Den! 5s                             0.000000\n",
       "Great! Sorcerer's of NY 2                          0.776156\n",
       "Great Secrets of Amazon                            0.000000\n",
       "S                                                  0.000000\n",
       "Ss                                                 0.000000\n",
       "7x7                                                0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=scores, index=docs1,\n",
    "             columns=[query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can get the matches directly based on the scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Potter #2 and the Chamber of Secrets',\n",
       " \"Harry Potter # and the Sorcerer's Stone\",\n",
       " \"Great! Sorcerer's of NY 2\",\n",
       " '7x7']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Harry Potter #2\"\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "\n",
    "top_n = bm25.get_top_n(tokenized_query, docs1, n=4)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can get the matches based on the scores in the tokenized form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['harry', 'potter', '#', '2', 'and', 'the', 'chamber', 'of', 'secrets'],\n",
       " ['harry', 'potter', '#', 'and', 'the', 'sorcerer', \"'s\", 'stone'],\n",
       " ['great', '!', 'sorcerer', \"'s\", 'of', 'ny', '2'],\n",
       " ['7x7']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Harry Potter #2\"\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "\n",
    "top_n = bm25.get_top_n(tokenized_query, tokenized_documents, n=4)\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop code execution\n",
    "\n",
    "10/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TFIDF + Cosine Similarity) vs BM25 - Output Check and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cs(docs1,query_str):\n",
    "    tf1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                     min_df=0)\n",
    "    tfidf1 = tf1.fit_transform(docs1)\n",
    "    cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "\n",
    "    return cosine_sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(docs1,query_str):\n",
    "    tokenized_query = word_tokenize(query_str.lower())\n",
    "    tokenized_documents = [word_tokenize(document.lower()) for document in docs1]\n",
    "    bm25 = BM25Okapi(tokenized_documents)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = pd.Series([\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "    \"Great Secrets of Amazon\",\n",
    "    \"S\",\n",
    "    \"Ss\",\n",
    "    \"7x7\",\n",
    "    \"Harry Harry Potter\",\n",
    "    \"Harry Potter Potter\",\n",
    "    \"Little Harry\",\n",
    "    \"Little Potter\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 0, 1, 11]\n",
      "[9, 8, 0, 11, 10]\n"
     ]
    }
   ],
   "source": [
    "query_str = \"Harry Potter\"\n",
    "\n",
    "data1 = list(reversed((np.argsort(tfidf_cs(docs1,query_str).flatten())[-5:])))\n",
    "data2 = list(reversed((np.argsort(bm25(docs1,query_str))[-5:])))\n",
    "\n",
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((np.reshape(docs1.iloc[data1].values,(-1,1)),np.reshape(docs1.iloc[data2].values,(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harry Potter-tfidf_cs</th>\n",
       "      <th>Harry Potter-bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter Potter</td>\n",
       "      <td>Harry Potter Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Harry Potter</td>\n",
       "      <td>Harry Harry Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter #2 and the Chamber of Secrets</td>\n",
       "      <td>Little Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Potter</td>\n",
       "      <td>Little Harry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Harry Potter-tfidf_cs  \\\n",
       "0                         Harry Potter Potter   \n",
       "1                          Harry Harry Potter   \n",
       "2     Harry Potter # and the Sorcerer's Stone   \n",
       "3  Harry Potter #2 and the Chamber of Secrets   \n",
       "4                               Little Potter   \n",
       "\n",
       "                         Harry Potter-bm25  \n",
       "0                      Harry Potter Potter  \n",
       "1                       Harry Harry Potter  \n",
       "2  Harry Potter # and the Sorcerer's Stone  \n",
       "3                            Little Potter  \n",
       "4                             Little Harry  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=data,\n",
    "             columns=[f\"{query_str}-tfidf_cs\",f\"{query_str}-bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 2, 11, 10]\n",
      "[3, 0, 2, 11, 10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sorcerer's Stone NY-tfidf_cs</th>\n",
       "      <th>Sorcerer's Stone NY-bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great! Sorcerer's of NY 2</td>\n",
       "      <td>Great! Sorcerer's of NY 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Sorcerer's Den! 5s</td>\n",
       "      <td>The Sorcerer's Den! 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Potter</td>\n",
       "      <td>Little Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Harry</td>\n",
       "      <td>Little Harry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sorcerer's Stone NY-tfidf_cs  \\\n",
       "0                Great! Sorcerer's of NY 2   \n",
       "1  Harry Potter # and the Sorcerer's Stone   \n",
       "2                   The Sorcerer's Den! 5s   \n",
       "3                            Little Potter   \n",
       "4                             Little Harry   \n",
       "\n",
       "                  Sorcerer's Stone NY-bm25  \n",
       "0                Great! Sorcerer's of NY 2  \n",
       "1  Harry Potter # and the Sorcerer's Stone  \n",
       "2                   The Sorcerer's Den! 5s  \n",
       "3                            Little Potter  \n",
       "4                             Little Harry  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Sorcerer's Stone NY\"\n",
    "\n",
    "data1 = list(reversed((np.argsort(tfidf_cs(docs1,query_str).flatten())[-5:])))\n",
    "data2 = list(reversed((np.argsort(bm25(docs1,query_str))[-5:])))\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "\n",
    "data = np.hstack((np.reshape(docs1.iloc[data1].values,(-1,1)),np.reshape(docs1.iloc[data2].values,(-1,1))))\n",
    "\n",
    "pd.DataFrame(data=data,\n",
    "             columns=[f\"{query_str}-tfidf_cs\",f\"{query_str}-bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 0, 1, 11]\n",
      "[0, 1, 9, 8, 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the Potter Harry-tfidf_cs</th>\n",
       "      <th>the Potter Harry-bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter Potter</td>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Harry Potter</td>\n",
       "      <td>Harry Potter #2 and the Chamber of Secrets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "      <td>Harry Potter Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter #2 and the Chamber of Secrets</td>\n",
       "      <td>Harry Harry Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Potter</td>\n",
       "      <td>The Sorcerer's Den! 5s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    the Potter Harry-tfidf_cs  \\\n",
       "0                         Harry Potter Potter   \n",
       "1                          Harry Harry Potter   \n",
       "2     Harry Potter # and the Sorcerer's Stone   \n",
       "3  Harry Potter #2 and the Chamber of Secrets   \n",
       "4                               Little Potter   \n",
       "\n",
       "                        the Potter Harry-bm25  \n",
       "0     Harry Potter # and the Sorcerer's Stone  \n",
       "1  Harry Potter #2 and the Chamber of Secrets  \n",
       "2                         Harry Potter Potter  \n",
       "3                          Harry Harry Potter  \n",
       "4                      The Sorcerer's Den! 5s  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"the Potter Harry\"\n",
    "\n",
    "data1 = list(reversed((np.argsort(tfidf_cs(docs1,query_str).flatten())[-5:])))\n",
    "data2 = list(reversed((np.argsort(bm25(docs1,query_str))[-5:])))\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "\n",
    "data = np.hstack((np.reshape(docs1.iloc[data1].values,(-1,1)),np.reshape(docs1.iloc[data2].values,(-1,1))))\n",
    "\n",
    "pd.DataFrame(data=data,\n",
    "             columns=[f\"{query_str}-tfidf_cs\",f\"{query_str}-bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 0, 1, 11]\n",
      "[0, 2, 3, 9, 8]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harry Potter Sorcerer's-tfidf_cs</th>\n",
       "      <th>Harry Potter Sorcerer's-bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter Potter</td>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Harry Potter</td>\n",
       "      <td>The Sorcerer's Den! 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter # and the Sorcerer's Stone</td>\n",
       "      <td>Great! Sorcerer's of NY 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter #2 and the Chamber of Secrets</td>\n",
       "      <td>Harry Potter Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Potter</td>\n",
       "      <td>Harry Harry Potter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Harry Potter Sorcerer's-tfidf_cs  \\\n",
       "0                         Harry Potter Potter   \n",
       "1                          Harry Harry Potter   \n",
       "2     Harry Potter # and the Sorcerer's Stone   \n",
       "3  Harry Potter #2 and the Chamber of Secrets   \n",
       "4                               Little Potter   \n",
       "\n",
       "              Harry Potter Sorcerer's-bm25  \n",
       "0  Harry Potter # and the Sorcerer's Stone  \n",
       "1                   The Sorcerer's Den! 5s  \n",
       "2                Great! Sorcerer's of NY 2  \n",
       "3                      Harry Potter Potter  \n",
       "4                       Harry Harry Potter  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Harry Potter Sorcerer's\"\n",
    "\n",
    "data1 = list(reversed((np.argsort(tfidf_cs(docs1,query_str).flatten())[-5:])))\n",
    "data2 = list(reversed((np.argsort(bm25(docs1,query_str))[-5:])))\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "\n",
    "data = np.hstack((np.reshape(docs1.iloc[data1].values,(-1,1)),np.reshape(docs1.iloc[data2].values,(-1,1))))\n",
    "\n",
    "pd.DataFrame(data=data,\n",
    "             columns=[f\"{query_str}-tfidf_cs\",f\"{query_str}-bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop code execution\n",
    "\n",
    "10/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine `nltk` for Vocabulary Generation and (`tfidf` + `Cosine Similarity`) for Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = [\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "    \"Great Secrets of Amazon\",\n",
    "    \"S\",\n",
    "    \"R\",\n",
    "    \"Ss\",\n",
    "    \"7x7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s', '#', '7x7', 'ny', '!', 'potter', 'great', 'den', \"'s\", 'r', 'stone', 'secrets', 'harry', 'amazon', 'chamber', 'the', '5s', 'of', 'sorcerer', 'ss', '2', 'and'}\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "vocabulary_set = set()\n",
    "\n",
    "for document in docs1:\n",
    "    vocabulary_set.update(word_tokenize(document.lower()))\n",
    "\n",
    "print(vocabulary_set)\n",
    "print(len(vocabulary_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting the vocabulary list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', \"'s\", '2', '5s', '7x7', 'amazon', 'and', 'chamber', 'den', 'great', 'harry', 'ny', 'of', 'potter', 'r', 's', 'secrets', 'sorcerer', 'ss', 'stone', 'the']\n"
     ]
    }
   ],
   "source": [
    "vocabulary_list = list(vocabulary_set)\n",
    "vocabulary_list.sort()\n",
    "print(vocabulary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 22)\n",
      "==================================================\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.41121476 0.         0.         0.         0.41121476\n",
      "  0.         0.         0.41121476 0.         0.         0.\n",
      "  0.35753936 0.         0.48686598 0.35753936]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.38031487 0.45028144 0.         0.         0.38031487\n",
      "  0.         0.3306728  0.38031487 0.         0.         0.38031487\n",
      "  0.         0.         0.         0.3306728 ]\n",
      " [0.         0.         0.         0.         0.56993279 0.\n",
      "  0.         0.         0.         0.56993279 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.41854106 0.         0.         0.41854106]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5054797  0.\n",
      "  0.59847285 0.43950001 0.         0.         0.         0.\n",
      "  0.43950001 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.58064508 0.         0.         0.         0.49042208 0.\n",
      "  0.         0.42640784 0.         0.         0.         0.49042208\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                    min_df=0, vocabulary=vocabulary_set)\n",
    "\n",
    "tfidf1 = tf1.fit_transform(docs1)\n",
    "\n",
    "print(tfidf1.toarray().shape)\n",
    "print(\"=\"*50)\n",
    "print(tfidf1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can observe that `'!', '#', \"'s\", '2', 's', 'r'` are not getting considered as matches although they are there in the vocabulary\n",
    "- `\"S\", \"R` are not getting considered as any valid vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['!', '#', \"'s\", '2', '5s', '7x7', 'amazon', 'and', 'chamber',\n",
       "       'den', 'great', 'harry', 'ny', 'of', 'potter', 'r', 's', 'secrets',\n",
       "       'sorcerer', 'ss', 'stone', 'the'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following vectors does not work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"#\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"2\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"s\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"s\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following vectors work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"5s\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"ss\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.64192944,\n",
       "        0.        , 0.54218382, 0.        , 0.        , 0.54218382,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Harry Potter Den!\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can clearly observe that there is a tfidf score for the terms `Harry`, `Potter`, `den` but there is no score for `!` although it is present in the Vocabulary\n",
    "- So, if the vector is a single character or the term is a single character then they are not considered in the above configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docs1 = [\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "    \"Great Secrets of Amazon\",\n",
    "    \"S\",\n",
    "    \"Ss\",\n",
    "    \"7x7\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44590798, 0.41240115, 0.36585663, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "\n",
    "cosine_sim1.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can observe that `Harry Potter Den!` has similarities in descending order as follows.\n",
    "\n",
    "```\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.56650157, 1.45587679, 2.38190502, 0.84766024, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Harry Potter Den!\"\n",
    "\n",
    "tokenized_query = word_tokenize(query_str.lower())\n",
    "\n",
    "tokenized_documents = [word_tokenize(document.lower()) for document in docs1]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can observe that `Harry Potter Den!` has similarities in descending order as follows.\n",
    "\n",
    "```\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'sorcerer', \"'s\", 'den', '!', '5s'],\n",
       " ['harry', 'potter', '#', 'and', 'the', 'sorcerer', \"'s\", 'stone'],\n",
       " ['harry', 'potter', '#', '2', 'and', 'the', 'chamber', 'of', 'secrets'],\n",
       " ['great', '!', 'sorcerer', \"'s\", 'of', 'ny', '2']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Harry Potter Den!\"\n",
    "\n",
    "tokenized_query = word_tokenize(query_str.lower())\n",
    "\n",
    "tokenized_documents = [word_tokenize(document.lower()) for document in docs1]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "top_n = bm25.get_top_n(tokenized_query, tokenized_documents, n=4)\n",
    "\n",
    "top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the tfidfVectorizer's default tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 16)\n"
     ]
    }
   ],
   "source": [
    "tf1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                    min_df=0)\n",
    "\n",
    "tfidf1 = tf1.fit_transform(docs1)\n",
    "\n",
    "print(tfidf1.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5s', '7x7', 'amazon', 'and', 'chamber', 'den', 'great', 'harry',\n",
       "       'ny', 'of', 'potter', 'secrets', 'sorcerer', 'ss', 'stone', 'the'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.64192944, 0.        , 0.54218382, 0.        , 0.        ,\n",
       "        0.54218382, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"Harry Potter Den!\"\n",
    "tf1.transform([query_str]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44590798, 0.41240115, 0.36585663, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "\n",
    "cosine_sim1.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Previous Data\n",
    "\n",
    "```\n",
    "docs1 = [\n",
    "    \"Harry Potter # and the Sorcerer's Stone\",\n",
    "    \"Harry Potter #2 and the Chamber of Secrets\",\n",
    "    \"The Sorcerer's Den! 5s\",\n",
    "    \"Great! Sorcerer's of NY 2\",\n",
    "    \"Great Secrets of Amazon\",\n",
    "    \"S\",\n",
    "    \"Ss\",\n",
    "    \"7x7\"\n",
    "]\n",
    "```\n",
    "\n",
    "```\n",
    "[0.44590798, 0.41240115, 0.36585663, 0.        , 0.        ,\n",
    "       0.        , 0.        , 0.        , 0.        ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can observe that the current score is same as the previous (tfidfVectorizer + Cosine Similary) score with external vocabulary\n",
    "- We can conclude that, with the above settings, the internal scoring takes place based on default tokenizer rule even if we add vocabulary from outside  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets try custom tokenizer directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # You can add additional processing or filtering steps here if needed\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 22)\n",
      "['!' '#' \"'s\" '2' '5s' '7x7' 'amazon' 'and' 'chamber' 'den' 'great'\n",
      " 'harry' 'ny' 'of' 'potter' 'r' 's' 'secrets' 'sorcerer' 'ss' 'stone'\n",
      " 'the']\n",
      "[[0.47663461 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.56432113 0.         0.47663461\n",
      "  0.         0.         0.47663461 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34421173, 0.31929011, 0.46459161, 0.18455746, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                    min_df=0, tokenizer=custom_tokenizer)\n",
    "\n",
    "tfidf1 = tf1.fit_transform(docs1)\n",
    "\n",
    "print(tfidf1.toarray().shape)\n",
    "print(tf1.get_feature_names_out())\n",
    "\n",
    "query_str = \"Harry Potter Den!\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "\n",
    "cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "cosine_sim1.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Following one is the score given by bm25\n",
    "  \n",
    "```\n",
    "[1.56650157, 1.45587679, 2.38190502, 0.84766024, 0.        ,\n",
    "       1.        , 0.        , 0.        , 0.        ]\n",
    "```\n",
    "\n",
    "- We can observe that the scoring pattern is same (although the scores are not)\n",
    "- We can also observe that, now the term '!' is getting considered during scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe the same for the rest of the terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "query_str = \"#\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "query_str = \"'s\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "query_str = \"2\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "query_str = \"r\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "query_str = \"s\"\n",
    "print(tf1.transform([query_str]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe the same for the vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"S\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "\n",
    "cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "cosine_sim1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"R\"\n",
    "print(tf1.transform([query_str]).toarray())\n",
    "\n",
    "cosine_sim1 = cosine_similarity(tfidf1, tf1.transform([query_str]))\n",
    "cosine_sim1.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
