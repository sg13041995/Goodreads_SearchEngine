{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "\n",
    "from configparser import ConfigParser\n",
    "from mysql.connector import MySQLConnection,Error\n",
    "from datetime import datetime\n",
    "\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': '127.0.0.1', 'port': '99966', 'database': 'gr_search_engine', 'user': 'root', 'password': 'Milla123!'}\n"
     ]
    }
   ],
   "source": [
    "# reading database credentials from config.ini file\n",
    "\n",
    "def read(filename='config.ini',section='mysql'):\n",
    "    parser=ConfigParser()\n",
    "    parser.read(filename)\n",
    "    \n",
    "    db={}\n",
    "    \n",
    "    if parser.has_section(section):\n",
    "        items=parser.items(section)\n",
    "        for item in items:\n",
    "            db[item[0]]=item[1]\n",
    "    else:\n",
    "        raise Exception(f'{section} not found in file {filename}')\n",
    "    return db \n",
    "\n",
    "\n",
    "print(read(filename=\"config.ini\",section=\"mysql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL database...\n",
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "# connecting with MySQL/MariaDB database server and getting the connection and cursor object\n",
    "\n",
    "def connect(creds):\n",
    "    con=None\n",
    "    try:\n",
    "        print('Connecting to MySQL database...')\n",
    "        con=MySQLConnection(**creds)\n",
    "        \n",
    "        \n",
    "        if con.is_connected():\n",
    "            print('Connection established')\n",
    "            cus = con.cursor(buffered=True)\n",
    "        else:\n",
    "            print('Connection failed')\n",
    "            \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        return con,cus\n",
    "    \n",
    "cn,cs=connect(creds=read(filename=\"config.ini\",section=\"mysql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required columns\n",
    "\n",
    "required_columns = [\n",
    "\"book_id\",\n",
    "\"gr_book_id\",\n",
    "\"title\",\n",
    "\"mod_title\",\n",
    "\"ratings_count\",\n",
    "\"average_rating\",\n",
    "\"link\",\n",
    "\"url\",\n",
    "\"image_url\",\n",
    "\"publication_day\",\n",
    "\"publication_month\",\n",
    "\"publication_year\",\n",
    "\"num_pages\",\n",
    "\"isbn\",\n",
    "\"isbn13\",\n",
    "\"description\",\n",
    "\"publisher\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json parser function into python dictionary\n",
    "\n",
    "def parse_fields(line):\n",
    "    data = json.loads(line)\n",
    "    data_dict = {\"book_id\" : None}\n",
    "\n",
    "    data_dict['gr_book_id'] = data['gr_book_id']\n",
    "    data_dict['title'] = data['title']\n",
    "    data_dict['mod_title'] = data['mod_title']\n",
    "    data_dict['ratings_count'] = data['ratings_count']\n",
    "    data_dict['average_rating'] = data['average_rating']\n",
    "    data_dict['link'] = data['link']\n",
    "    data_dict['url'] = data['url']\n",
    "    data_dict['image_url'] = data['image_url']\n",
    "    data_dict['publication_day'] = int(data['publication_day'])\n",
    "    data_dict['publication_month'] = int(data['publication_month'])\n",
    "    data_dict['publication_year'] = int(data['publication_year'])\n",
    "    data_dict['num_pages'] = int(data['num_pages'])\n",
    "    data_dict['isbn'] = int(data['isbn'])\n",
    "    data_dict['isbn13'] = int(data['isbn13'])\n",
    "    data_dict['description'] = data['description']\n",
    "    data_dict['publisher'] = data['publisher']\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"isbn\":0.0,\"average_rating\":4.03,\"similar_books\":[\"19997\",\"828466\",\"1569323\",\"425389\",\"1176674\",\"262740\",\"3743837\",\"880461\",\"2292726\",\"1883810\",\"1808197\",\"625150\",\"1988046\",\"390170\",\"2620131\",\"383106\",\"1597281\"],\"description\":\"Omnibus book club edition containing the Ladies of Madrigyn and the Witches of Wenshar.\",\"link\":\"https:\\\\/\\\\/www.goodreads.com\\\\/book\\\\/show\\\\/7327624-the-unschooled-wizard\",\"authors\":[{\"author_id\":\"10333\",\"role\":\"\"}],\"publisher\":\"Nelson Doubleday, Inc.\",\"num_pages\":600.0,\"publication_day\":0.0,\"publication_month\":0.0,\"publication_year\":1987.0,\"isbn13\":0.0,\"url\":\"https:\\\\/\\\\/www.goodreads.com\\\\/book\\\\/show\\\\/7327624-the-unschooled-wizard\",\"image_url\":\"https:\\\\/\\\\/images.gr-assets.com\\\\/books\\\\/1304100136m\\\\/7327624.jpg\",\"gr_book_id\":7327624,\"ratings_count\":140,\"title\":\"The Unschooled Wizard (Sun Wolf and Starhawk, #1-2)\",\"mod_title\":\"the unschooled wizard sun wolf and starhawk 12\"}\\r\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the first line/record from the compressed json file in a streaming fashion\n",
    "\n",
    "with gzip.open(\"../../Datasets/Processed/SE/books_ratingcount_gt15_p2.json.gz\") as f:\n",
    "    line = f.readline()\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_id': None,\n",
       " 'gr_book_id': 7327624,\n",
       " 'title': 'The Unschooled Wizard (Sun Wolf and Starhawk, #1-2)',\n",
       " 'mod_title': 'the unschooled wizard sun wolf and starhawk 12',\n",
       " 'ratings_count': 140,\n",
       " 'average_rating': 4.03,\n",
       " 'link': 'https://www.goodreads.com/book/show/7327624-the-unschooled-wizard',\n",
       " 'url': 'https://www.goodreads.com/book/show/7327624-the-unschooled-wizard',\n",
       " 'image_url': 'https://images.gr-assets.com/books/1304100136m/7327624.jpg',\n",
       " 'publication_day': 0,\n",
       " 'publication_month': 0,\n",
       " 'publication_year': 1987,\n",
       " 'num_pages': 600,\n",
       " 'isbn': 0,\n",
       " 'isbn13': 0,\n",
       " 'description': 'Omnibus book club edition containing the Ladies of Madrigyn and the Witches of Wenshar.',\n",
       " 'publisher': 'Nelson Doubleday, Inc.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsing json record into dictionary and storing that\n",
    "\n",
    "test_record = parse_fields(line)\n",
    "test_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL insert query => insert one record at a time\n",
    "\n",
    "# insert function takes following parameters\n",
    "# the non-transformed raw record as dictionary\n",
    "# connection and cursor object \n",
    "\n",
    "# name of the table\n",
    "table = \"book\"\n",
    "\n",
    "def insert_one(record_json, table=table, cn=cn, cs=cs):\n",
    "    columns_string = \"\"\"\n",
    "    book_id,\n",
    "    gr_book_id,\n",
    "    title,\n",
    "    mod_title,\n",
    "    ratings_count,\n",
    "    average_rating,\n",
    "    link,\n",
    "    url,\n",
    "    image_url,\n",
    "    publication_day,\n",
    "    publication_month,\n",
    "    publication_year,\n",
    "    num_pages,\n",
    "    isbn,\n",
    "    isbn13,\n",
    "    description,\n",
    "    publisher,\n",
    "    status, \n",
    "    created_id,\n",
    "    created_dtm,\n",
    "    modified_id,\n",
    "    modified_dtm\n",
    "    \"\"\"\n",
    "\n",
    "    # placeholders as string\n",
    "    place_holders = \"\"\"\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s,\n",
    "    %s\n",
    "    \"\"\"\n",
    "    record_dict = parse_fields(record_json)\n",
    "\n",
    "    # accessing the dict data to prepare the data as tuple\n",
    "    data_tuple = list(record_dict.values())\n",
    "\n",
    "    # adding the vales of last 5 standard columns\n",
    "    data_tuple = tuple(data_tuple + list((1,1,datetime.now(),1,datetime.now())))\n",
    "\n",
    "    # SQL query to insert the data\n",
    "    sql_query = f\"\"\"\n",
    "    INSERT INTO {table} ({columns_string})\n",
    "    VALUES ({place_holders});\n",
    "    \"\"\"\n",
    "\n",
    "    # trying to execute the query\n",
    "    try:\n",
    "        cs.execute(sql_query, data_tuple)\n",
    "        cn.commit()\n",
    "    # throwing error in case of unsuccessful attempt\n",
    "    except Error as e:\n",
    "        raise Exception(f\"{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the data insert function\n",
    "\n",
    "# insert_one(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will go through all the books from the dataset and insert them one after the other\n",
    "# runtime 40 m\n",
    "\n",
    "books = []\n",
    "\n",
    "with gzip.open(\"../../Datasets/Processed/SE/books_ratingcount_gt15_p2.json.gz\") as f:\n",
    "    while True:\n",
    "        # reading the line as json\n",
    "        line = f.readline()\n",
    "\n",
    "        # we will break the infinite loop when we reach the end of the dataset file\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        # insert function to upload the data into database\n",
    "        insert_one(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
